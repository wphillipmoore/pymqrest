# AI-assisted engineering

## Transparency statement

`pymqrest` is an AI-assisted engineering project. Significant portions of
the codebase were developed collaboratively between a human engineer and
AI coding agents. This page documents what was AI-generated, what was
human-designed, and how quality was maintained.

### Tools used

- **Claude Code** (Anthropic) — interactive pair-programming agent
- **Codex** (OpenAI) — autonomous task execution agent

## What was AI-generated

**Mapping data bootstrap**: The `MAPPING_DATA` structure in
`mapping_data.py` was originally bootstrapped from IBM MQ 9.4
documentation using an AI-assisted extraction pipeline. The pipeline
parsed MQSC and PCF command references to propose `snake_case` attribute
names, value mappings, and command metadata for all 48 qualifiers. The
automated output was then reviewed, customized, and rationalized by hand.
`mapping_data.py` is now maintained directly as the sole authoritative
source — the extraction pipeline is archived in
`docs/archive/extraction/`. See {doc}`/development/namespace-origin` for
the full history and the strategy for future MQ versions.

**Command method generation**: The ~144 MQSC command wrapper methods in
`commands.py` are generated from the command definitions in
`MAPPING_DATA`. Each method is a thin wrapper with the correct verb,
qualifier, and return type.

**Mapping documentation**: The 48 qualifier mapping pages in this
documentation were generated by `scripts/dev/generate_mapping_docs.py`
from the same `MAPPING_DATA` source.

**Implementation code**: Much of the session, mapping, and test code was
written through AI-assisted pair programming, with the AI agent proposing
implementations and the human engineer reviewing, refining, and directing
the design.

## What was human-designed

**Architecture and API design**: The overall design — single-endpoint via
`runCommandJSON`, qualifier-based mapping, method naming conventions,
return shape rules, error handling strategy — was conceived and directed
by the human engineer.

**Quality standards**: The requirement for 100% test coverage, strict
typing (mypy + ty), comprehensive linting (all ruff rules), and the
validation gate pipeline were human-defined standards.

**Design decisions**: Key choices like the mapping opt-out mechanism,
strict vs lenient modes, the transport abstraction, and the diagnostic
state interface were human decisions refined through discussion.

## Quality assurance

The AI-assisted development process maintains quality through:

**100% test coverage**: Every line and branch of production code is
covered by unit tests. Coverage is enforced as a CI hard gate.

**Strict typing**: Both mypy and ty type checkers run in strict mode
against the entire source tree.

**Comprehensive linting**: Ruff runs with all rule categories enabled.
The few per-file exceptions (like missing docstrings in generated code)
are explicitly configured.

**Validation pipeline**: `scripts/dev/validate_local.py` runs the same
checks as CI, including dependency auditing, lock file verification,
and commit message validation.

**Integration testing**: A containerized IBM MQ queue manager provides
real MQSC command validation. Integration tests verify that mapping
assumptions hold against actual MQ responses.

## The `Co-Authored-By` convention

Commits that involved AI assistance include a `Co-Authored-By` trailer
identifying the agent used:

```
Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>
Co-Authored-By: Codex <noreply@openai.com>
```

This provides a transparent, auditable record of AI involvement in the
project's git history.
